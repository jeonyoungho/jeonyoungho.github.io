<!DOCTYPE html><html lang="ko" mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="Kafka 개요" /><meta name="author" content="jeonyoungho" /><meta property="og:locale" content="ko" /><meta name="description" content="MessageQueue 데이터를 전송하는 애플리케이션과 데이터를 수신 받는 애플리케이션의 개수가 늘어날 수 록 데이터 전송라인이 많아 지게 됨 데이터 전송라인이 많아지면 배포와 장애에 대응하기 어려움 데이터를 전송할 때의 프로토콜의 파편화가 심각해짐 추후 데이터의 포맷내부에 변경이 있을 때 유지보수하기 매우 어려워짐 카프카는 이런 복잡함을 해결하기 위해 링크드인에서 내부적으로 개발하였고 현재는 오픈 소스로 제공 Source Application과 TargetAppliction의 커플링을 약하게 해줌 Source Application은 카프카에 데이터를 전송하면 되고 Target Application은 데이터를 가져오기만 하면 됨 방대한 양의 클릭로그, 결제로그와 같은 데이터들을 안전하게 처리 json, tsv, avo등 여러 데이터 포맷을 지원함 Kafka Producer는 데이터를 집어넣는 역할, 즉 Source Application이 되며 Kafka Consumer는 데이터를 빼서 쓰는 역할을 함 Producer, Consumer는 라이브러리로 구현되어 다양한 언어로 지원 낮은 지연과 높은 처리량으로 대량의 데이터를 효과적으로 처리" /><meta property="og:description" content="MessageQueue 데이터를 전송하는 애플리케이션과 데이터를 수신 받는 애플리케이션의 개수가 늘어날 수 록 데이터 전송라인이 많아 지게 됨 데이터 전송라인이 많아지면 배포와 장애에 대응하기 어려움 데이터를 전송할 때의 프로토콜의 파편화가 심각해짐 추후 데이터의 포맷내부에 변경이 있을 때 유지보수하기 매우 어려워짐 카프카는 이런 복잡함을 해결하기 위해 링크드인에서 내부적으로 개발하였고 현재는 오픈 소스로 제공 Source Application과 TargetAppliction의 커플링을 약하게 해줌 Source Application은 카프카에 데이터를 전송하면 되고 Target Application은 데이터를 가져오기만 하면 됨 방대한 양의 클릭로그, 결제로그와 같은 데이터들을 안전하게 처리 json, tsv, avo등 여러 데이터 포맷을 지원함 Kafka Producer는 데이터를 집어넣는 역할, 즉 Source Application이 되며 Kafka Consumer는 데이터를 빼서 쓰는 역할을 함 Producer, Consumer는 라이브러리로 구현되어 다양한 언어로 지원 낮은 지연과 높은 처리량으로 대량의 데이터를 효과적으로 처리" /><link rel="canonical" href="https://jeonyoungho.github.io/posts/Kafka-%EA%B0%9C%EC%9A%94/" /><meta property="og:url" content="https://jeonyoungho.github.io/posts/Kafka-%EA%B0%9C%EC%9A%94/" /><meta property="og:site_name" content="Youngho’s Devlog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-06-30T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Kafka 개요" /><meta name="twitter:site" content="@jeonyoungho_o" /><meta name="twitter:creator" content="@jeonyoungho" /><meta name="google-site-verification" content="eonGeSiIVfF48EnFoJqakC7h2hUzgqxFNJaxkfPiGr0" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"jeonyoungho"},"dateModified":"2021-06-30T00:00:00+09:00","datePublished":"2021-06-30T00:00:00+09:00","description":"MessageQueue 데이터를 전송하는 애플리케이션과 데이터를 수신 받는 애플리케이션의 개수가 늘어날 수 록 데이터 전송라인이 많아 지게 됨 데이터 전송라인이 많아지면 배포와 장애에 대응하기 어려움 데이터를 전송할 때의 프로토콜의 파편화가 심각해짐 추후 데이터의 포맷내부에 변경이 있을 때 유지보수하기 매우 어려워짐 카프카는 이런 복잡함을 해결하기 위해 링크드인에서 내부적으로 개발하였고 현재는 오픈 소스로 제공 Source Application과 TargetAppliction의 커플링을 약하게 해줌 Source Application은 카프카에 데이터를 전송하면 되고 Target Application은 데이터를 가져오기만 하면 됨 방대한 양의 클릭로그, 결제로그와 같은 데이터들을 안전하게 처리 json, tsv, avo등 여러 데이터 포맷을 지원함 Kafka Producer는 데이터를 집어넣는 역할, 즉 Source Application이 되며 Kafka Consumer는 데이터를 빼서 쓰는 역할을 함 Producer, Consumer는 라이브러리로 구현되어 다양한 언어로 지원 낮은 지연과 높은 처리량으로 대량의 데이터를 효과적으로 처리","headline":"Kafka 개요","mainEntityOfPage":{"@type":"WebPage","@id":"https://jeonyoungho.github.io/posts/Kafka-%EA%B0%9C%EC%9A%94/"},"url":"https://jeonyoungho.github.io/posts/Kafka-%EA%B0%9C%EC%9A%94/"}</script><title>Kafka 개요 | Youngho's Devlog</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Youngho's Devlog"><meta name="application-name" content="Youngho's Devlog"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script async src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-RF6ZGDWXV1"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-RF6ZGDWXV1'); }); </script> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5958719204143086" crossorigin="anonymous"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/youngho_employee_pic.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Youngho's Devlog</a></div><div class="site-subtitle font-italic">curios developer</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/jeonyoungho" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/jeonyoungho_o" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['yhjun1000','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Kafka 개요</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"> <ins class="adsbygoogle" style="display:block; margin-top: 30px;" data-ad-client="ca-pub-5958719204143086" data-ad-slot="1982371670" data-ad-format="auto" data-full-width-responsive="true"></ins> <script> (adsbygoogle = window.adsbygoogle || []).push({}); </script><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Kafka 개요</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> jeonyoungho </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Wed, Jun 30, 2021, 12:00 AM +0900" prep="on" > Jun 30, 2021 <i class="unloaded">2021-06-30T00:00:00+09:00</i> </span></div><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="4308 words">23 min</span></div></div><div class="post-content"><h1 id="messagequeue">MessageQueue</h1><ul><li>데이터를 전송하는 애플리케이션과 데이터를 수신 받는 애플리케이션의 개수가 늘어날 수 록 데이터 전송라인이 많아 지게 됨<br /><li>데이터 전송라인이 많아지면 배포와 장애에 대응하기 어려움<br /><li>데이터를 전송할 때의 프로토콜의 파편화가 심각해짐<br /><li>추후 데이터의 포맷내부에 변경이 있을 때 유지보수하기 매우 어려워짐<br /><li>카프카는 이런 복잡함을 해결하기 위해 링크드인에서 내부적으로 개발하였고 현재는 오픈 소스로 제공<br /><li>Source Application과 TargetAppliction의 커플링을 약하게 해줌<li>Source Application은 카프카에 데이터를 전송하면 되고 Target Application은 데이터를 가져오기만 하면 됨<br /><li>방대한 양의 클릭로그, 결제로그와 같은 데이터들을 안전하게 처리<li>json, tsv, avo등 여러 데이터 포맷을 지원함<br /><li>Kafka Producer는 데이터를 집어넣는 역할, 즉 Source Application이 되며 Kafka Consumer는 데이터를 빼서 쓰는 역할을 함<br /><li>Producer, Consumer는 라이브러리로 구현되어 다양한 언어로 지원<br /><li>낮은 지연과 높은 처리량으로 대량의 데이터를 효과적으로 처리<br /> <img width="878" alt="스크린샷 2020-11-30 오후 10 15 43" src="https://user-images.githubusercontent.com/44339530/100614510-97fd5500-3359-11eb-9d71-379cbdc2414b.png" /><br /></ul><h1 id="topic">Topic</h1><ul><li><img width="878" alt="스크린샷 2020-11-30 오후 10 24 26" src="https://user-images.githubusercontent.com/44339530/100615336-d0516300-335a-11eb-9166-86674444b164.png" /><br /><li>카프카에서는 토픽을 여러 개 생성 가능<br /><li>목적에 따라 무슨 데이터를 담는지 명확히 명시하여 유지보수가 편리함<br /><li>하나의 파티션은 내부의 0번 인덱스부터 순서대로 쌓이게 됨<br /><li>컨슈머가 붙으면 데이터를 낮은 인덱스의 데이터부터 가져가게 됨<br /><li>컨슈머가 파티션 내부에서 데이터를 가져가더라도 데이터는 삭제되지 않음<br /><li>새로운 컨슈머가 붙었을때 0번 부터 새로 가져가게 됨 (단, 컨슈머 그룹이 달라야 하고 auto.offset.reset=earliest로 설정되있어야함)<br /><li>데이터의 유실도 방지하며 동일 데이터를 여러 번 사용 가능<li>클릭로그를 분석하고 시각화하기 위해 엘라스틱 서치에 저장하기도 하고 백업하기 위해 Hadoop에 저장하기도 함<br /><li><img width="878" alt="스크린샷 2020-11-30 오후 10 26 25" src="https://user-images.githubusercontent.com/44339530/100615561-173f5880-335b-11eb-94e8-220341a608f0.png" /><br /><li>다음 그림과 같이 키가 null이고, 기본 파티셔너를 사용할 경우 데이터는 라운드로빈 방식으로 할당이되고 키가 있고 기본파티셔너를 사용할 경우 키의 해시 값을 구하여 특정 파티션에 할당되어짐<br /><li>파티션을 늘리면 컨슈머의 개수를 늘려서 데이터 처리를 분산시킬 수 있음<br /><li>파티션을 늘리는 건 가능하지만 줄일 수는 없음<br /><li>파티션의 데이터는 옵션에 따라 삭제되는 시기가 다름<br /><ul><li>log.retention.ms: 최대 record보존 기간<br /><li>log.retention.byte: 최대 record보존 크기(byte)<br /></ul></ul><h1 id="producer">Producer</h1><ul><li>데이터를 카프카에 보내는 역할<br /><li>대량의 데이터를 실시간으로 카프카에 적재할 수 있음<br /><li>프로듀서의 역할<br /><ul><li>Topic에 해당하는 메시지를 생성<br /><li>특정 Topic으로 데이터를 publish<br /><li>처리 실패/재시도 (전송성공 여부를 알 수 있고 재시도 할 수 있음)<br /></ul><li>Gradle이나 Maven으로 라이브러리를 가져 올 수 있으며 Client버전과 Broker버전을 일치시켜주는게 좋음<br /></ul><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre>// gradle
compile group: 'org.apache.kafka', name: 'kafka-clients', version: '2.3.0'

//maven
&lt;dependency&gt;
  &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
  &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
  &lt;version&gt;2.3.0&lt;/version&gt;
&lt;/dependency&gt;
</pre></table></code></div></div><ul><li>예제 코드<br /><ul><li><img width="878" alt="스크린샷 2020-11-30 오후 10 34 58" src="https://user-images.githubusercontent.com/44339530/100616322-4904ef00-335c-11eb-85bd-bec544f6fca0.png" /><br /></ul><li>브로커의 주소목록은 2개 이상의 ip와 port를 지정하도록 권장 (한 개 브로커가 비정상일 경우 다른 브로커를 사용할 수 있기 때문에)<br /><li>StringSerializer는 key혹은 value를 직렬화하기 위해 사용(byte array, string, integer 시리얼라이즈 사용 가능)<br /><li>키는 메시지를 보내면, 토픽의 파티션이 지정될 때 쓰임<br /><li>ProduceRecord를 생성할 때 인자로 토픽하고 key, value를 지정<br /></ul><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>producer.send(new ProducerData&lt;String, String&gt;("TopicName", "KeyName", "Value"));
</pre></table></code></div></div><ul><li>카프카는 키를 특정한 해쉬값으로 변환시켜 파티션과 1대1 매칭을 시키게 됨<br /><li>키와 파티션의 매칭이 깨지게되면 일관성이 보장되지 않음<br /></ul><h1 id="broker">Broker</h1><ul><li>카프가 설치되어 있는 서버 단위<br /><li>보통 세 개 이상의 브로커를 구성하여 사용하는 것을 권장<br /><li><img width="878" alt="스크린샷 2020-11-30 오후 10 46 20" src="https://user-images.githubusercontent.com/44339530/100617449-deed4980-335d-11eb-8f2a-530cc65a0fd6.png" /><br /><ul><li><b>replication</b>은 파티션의 복제를 뜻함<br /><li>클러스터에서 서버에 장애가 생겼을 때 가용성을 보장<br /><li><b>카프카 아키텍쳐의 핵심</b><br /><ul><li>만약 repliaction이 1이라면 파티션이 1개만 존재<br /><li>만약 repliaction이 2이라면 원본 파티션1개, 복제본 파티션1개 존재<br /><li>만약 repliaction이 3이라면 원본 파티션1개, 복제본 파티션2개 존재<br /><li>여기서 원본 파티션은 Leader Partion이라 부르고 복제본 파티션은 Follower Partion이라 부름<br /><li><img width="878" alt="스크린샷 2020-11-30 오후 10 50 56" src="https://user-images.githubusercontent.com/44339530/100617943-836f8b80-335e-11eb-8c35-afd6e199000f.png" /><li>다만 브로커 개수에 따라 replication의 개수는 제한이 됨<br /><li>replication의 개수는 broker의 개수보다 많아질 수 없음<br /><ul><li>broker의 개수가 3이면 replication의 개수는 4가 될 수 없음<br /></ul><li>leader partion과 follower partion을 합쳐서 <b>In Sync Replica(ISR)</b>라고도 부름<br /><li>만약 브로커가 3개인 카프카에서 repliaction이 1이고 partion이 1인 topic이 존재한다고 가정했을 때 브로커가 중단된다면 더 이상 해당 파티션을 복구가 될 수 없음<br /><li>만약 replication이 2라면 브로커 1개가 죽더라도 follower partion이 leader partion의 역할을 승계하게 됨<br /><li>프로듀서가 토픽에 데이터를 전달할 때 Leader Partion이 데이터를 전달 받는 주체가 됨<br /><li>프로듀서에는 ack옵션을 통해 고가용성을 유지할 수 있는데 partion의 replication과 관련이 있음<br /><li>ack는 0, 1, all 옵션 3개 중 1개를 골라서 설정 가능<br /><ul><li>0일 경우 프로듀서는 leader partion에 데이터를 전송하고 응답값을 받지 않기에 정상적으로 전송됐는지 또는 나머지 파티션에 정상적으로 복제 됐는지 알 수 없고 보장할 수 없음(속도는 빠르지만 데이터 유실 가능성 존재)<br /><li>1일 경우 leader partion에 데이터를 전송하고 제대로 전송됐는지 응답값을 받지만 replication이 정상적으로 복제 됐는지는 알 수 없음(만약 leader partion이 데이터를 받자마자 장애가 나면 나머지 partion에 데이터가 미처 전송되지 못한 상태이므로 데이터 유실 가능성이 존재)<br /><li>all일 경우 1옵션에 추가로 follower partion에 복제가 잘 이뤄줬는지까지 응답값을 받게 됨(데이터 유실 없지만 속도가 현저히 느린 단점 존재)<br /></ul><li>하지만 무작정 replication개수를 늘리면 브로커의 리소스 사용량도 늘어나게 됨<br /><li>따라서 카프카에 들어오는 데이터량과 저장 시간을 고려해서 replication을 정하는게 좋음<br /><li>3개 이상의 브로커를 사용할 때 replication은 3으로 설정하는 것을 권장<br /></ul></ul></ul><h1 id="consumer">Consumer</h1><ul><li><b>다른 메시징 시스템과 다르게 메시지를 가져가더라도 데이터가 사라지지 않음</b><br /><li>이와 같은 특징은 카프카, 그리고 카프카 컨슈머를 데이터 파이프라인으로 운영하는데 핵심적인 역할을 함<br /><li>Consumer의 역할<ul><li>Topic의 partion으로 부터 데이터를 가져옴(polling)<br /><li>partion offset(파티션에 위치해있는 데이터의 번호) 위치 기록(commit)<br /><li>Consumer group을 통해 병렬처리<br /></ul><li>Gradle이나 Maven으로 라이브러리를 가져 올 수 있으며 Client버전과 Broker버전을 일치시켜주는게 좋음<br /></ul><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre>// gradle
compile group: 'org.apache.kafka', name: 'kafka-clients', version: '2.3.0'

//maven
&lt;dependency&gt;
  &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
  &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
  &lt;version&gt;2.3.0&lt;/version&gt;
&lt;/dependency&gt;
</pre></table></code></div></div><ul><li>예제 코드<br /><li><img width="878" alt="스크린샷 2020-11-30 오후 11 15 38" src="https://user-images.githubusercontent.com/44339530/100620621-f6c6cc80-3361-11eb-9e43-0b703901ee32.png" /><br /><li>브로커의 주소목록은 2개 이상의 ip와 port를 지정하도록 권장 (한 개 브로커가 비정상일 경우 다른 브로커를 사용할 수 있기 때문에)<br /><li>Consumer group id를 지정해야함<br /><li>StringDeSerializer는 key혹은 value를 직렬화 설정해야함(byte array, string, integer 시리얼라이즈 사용 가능)<br /><li>특정 토픽의 전체 파티션이 아닌 특정 파티션에서 데이터를 가져오고자 한다면 다음과 같이 설정<br /><li><img width="878" alt="스크린샷 2020-11-30 오후 11 18 17" src="https://user-images.githubusercontent.com/44339530/100620918-5624dc80-3362-11eb-9d42-6cb79bd8c675.png" /><br /><li>polling한 데이터를 하둡 또는 엘라스틱서치와 같은 저장소에 저장하기도 함<br /><li>Consumer는 partion에 접근해서 __consumer_offsets토픽에 offset에 대한 정보들을 기록하며 데이터를 가져감<br /><li>만약 Consumer가 의도치 않게 중단되도 어디까지 읽었는지에 대한 offset정보는 __consumer_offsets에 이미 저장되있기에 컨슈머를 재실행해도 중지되었던 시점부터 제대로 데이터를 읽어들일 수 있음(고가용성)<br /><li>Partition과 Consumer의 개수<br /><ul><li>하나의 Consumer는 하나의 Partion을 subscribe<br /><li>Partition은 하나의 Consumer만 접근이 가능<br /><li>반대로 Consumer는 여러 개의 Partition을 소비할 수 있음<br /><li><p>대량의 메시지가 Kafka에 쓰여진다고 가정<br /></p><li><b>(1) Partition 1개 / Consumer 인스턴스 1</b><ul><li>메시지가 대량으로 막 생산되고 있는데, 처리할 수 있는 Consumer가 1개 밖에 없으니 그래서 Consumer를 늘리기로 함.</ul><li><b>(2) Partition 1개 / Consumer 인스턴스 4개</b><ul><li>Consumer를 4개로 늘렸지만, Consumer Group에서 Partition은 하나의 Consumer 밖에 접근을 못하는 구조<li>즉, Consumer를 늘리나 마나인 상황이라 그래서 이번에는 Partition을 늘림</ul><li><b>(3) Partition 4개 / Consumer 인스턴스 4개</b><ul><li>Consumer는 하나의 Partition에 접근할 수 있으므로, Partition과 Consumer는 1:1 구성<li>이상적인 상황</ul><li><b>(4) Partition 4개 / Consumer 인스턴스 3개</b><ul><li>잘 운영이 되다가, 갑자기 Consumer 하나가 죽어버려도 문제는 없음<li>Consumer Group에서 offset이 공유되고 있으므로 Consumer가 하나 죽더라도 다른 Consumer가 해당 Partition에 접근하면 됨</ul><li><b>(5) Partition 3개 / Consumer 인스턴스 3개</b><ul><li>메시지가 잘 처리되고 있고, 상황을 보니 Partition을 3개로 줄여도 될 것 같지만 Partition은 한 번 늘리면 줄일수가 없음</ul><li>위 상황의 결론은 Partition의 개수 &gt;= Consumer 인스턴스의 갯수를 유지하는 것이 좋음( Consumer &gt; Partition은 불가능 )<li>하나의 Partition에 하나의 Consumer가 담당하는 것이 좋지만 딱 맞출수는 없으므로, Consumer 수가 모자라도 상관은 없음<li>주의할 점은 한 번 Partition을 늘리면 다시 줄일 수 없기 때문에, 처리량을 잘 고려하여 Partition과 Consumer의 개수를 선택해야 할 것<br /></ul></ul><h1 id="consumer-group">Consumer Group</h1><ul><li><b>왜 Consumer Group이 필요한가?</b><ul><li>만약 Consumer Group이 없고 두 개의 Consumer가 하나의 Partion에 동시에 접근한다면 어떤 Consumer가 몇 번의 offset을 소비해야하는지 알 수가 없게 됨<br /><li>그리고 Consumer Group이 어떤 Consumer가 해당 partion의 몇 번 offset을 소비해야하는지에 대한 정보들을 다 가지고 있기 때문에 Consumer하나가 다운 되어도 다른 Consumer가 해당 파티션의 메시지를 소비할 수 있도록함(고가용성 확보)<br /></ul><li>Consumer는 하나의 Consumer Group에 속하며 Consumer Group은 하나의 Topic을 Subscribe<br /><li>각기 다른 Consumer Group에 속한 Consumer들은 서로 영향을 끼치지 않음<br /><li><b>Consumer Group의 활용</b><br /><ul><li>데이터 실시간 시각화 및 분석을 위해 엘라스틱 서치에 데이터를 저장하는 Consumer Group이 있다고 가정<br /><li><img width="878" alt="스크린샷 2020-11-30 오후 11 32 17" src="https://user-images.githubusercontent.com/44339530/100622522-4a3a1a00-3364-11eb-98f0-2c437c3bf4ad.png" /><br /><li>여기에 추가로 데이터 백업 용도로 하둡에 데이터를 저장하는 Consumer Group이 새로 들어옴<br /><li><img width="878" alt="스크린샷 2020-11-30 오후 11 33 46" src="https://user-images.githubusercontent.com/44339530/100622691-7f466c80-3364-11eb-899c-e4d6d7ccffa9.png" /><br /><li>만약 엘라스틱 서치에 저장하는 Consumer Group이 각 파티션에 특정 offset을 읽고 있어도 하둡에 저장하는 Consumer Group이 데이터를 읽는데 영향을 미치지 않음<br /><li>왜냐하면 __consumer_offsets토픽에는 컨슈머 그룹별로 토픽별로 offset을 나눠 저장하기 때문<br /><li>이러한 카프카의 특징을 토대로 하나의 Topic으로 들어온 데이터는 다양한 역할을 하는 여러 Consumer들이 각자 원하는 데이터로 처리가 될 수 있음<br /></ul></ul><h1 id="consumer-design-kafka의-이점">Consumer Design (Kafka의 이점)</h1><ul><li><p>Kafka와 마찬가지로 대표적인 메시징 시스템인 RabbitMQ, ActiveMQ 역시 분산 큐 시스템(Distributed Queue System)이니까 성능이 다 빠를것 같은데.. 왜 유독 Kafka가 빠르다고 할까?</p><li>성능이 좋으려면 Consumer가 최대의 효율을 내야 함<li>분산처리가 된다한들, 소비자가 메시지를 처리못하면 전체적인 성능이 느려지게됨<li>즉, 메시지를 소비하는 방식에 대한 차이가 성능의 차이를 나타내게 됨<li>Kafka는 Single Consumer가 아닌, Multi Consumer를 염두에 두고 설계되었기 때문에 Consumer를 잘 살펴볼 필요가 있음</ul><h1 id="rabbitmq와-kafka의-consumer-design의-비교">RabbitMQ와 Kafka의 Consumer Design의 비교</h1><ul><li>1)RabbitMQ<ul><li>Message Broker가 Consumer에게 메시지를 push하는 방식<li>Broker는 Consumer의 처리여부에 관계없이 push를 하므로, 메시지 소비 속도보다 생산 속도가 빠를 경우 Consumer에 부하를 주게됨<li>RabbitMQ는 DRAM을 사용하므로 buffer를 사용하지만, DRAM을 다 사용하면 disk에 저장, 따라서 batch 같이 큰 작업에서는 disk로 메시지를 읽어올 경우 지연이 발생</ul><li>2)Kafka<ul><li>Consumer가 Broker로부터 메시지를 pull하는 방식<li>Consumer가 처리할 수 있을 때 메시지를 가져오므로 자원을 효율적으로 사용<li>Kafka는 애초에 메시지를 disk에 저장하고, 이미 처리한 과거의 offset으로 자유롭게 움직일 수 있으므로 batch 작업에서 자원의 낭비라던지 지연이 발생하지 않음<li>메시지를 쌓아두었다가 처리하는 batch Consumer 구현도 가능</ul><li>항상 trade off가 있듯이, pull 방식에도 단점은 있음<li>데이터가 없음에도 정기적인 polling으로 인해 자원을 낭비하는 문제인데, 이러한 단점을 보완하기 위해 실제 데이터가 도착할 때까지 long poll 대기를 할 수 있는 parameter를 지원<br /> (kafka공식문서 참고 https://kafka.apache.org/documentation/#design_pull)<br /></ul><h1 id="replication">Replication</h1><ul><li>Topic을 생성할 때, –replication-factor 옵션을 부여하면 복제본(replication)을 생성<li>Replication이란 Zookeeper가 leader가 되는 Partition을 정하고, Partition을 각 broker마다 복제를 하는 것, 이때 leader를 복제하는 partition을 follower라 칭함<ul><li>leader: 메시지를 생산하고 소비하는 작업은 모두 leader broker에서 이뤄짐<li>follower: 나머지 follower들은 leader를 복제만 수행</ul><li>이는 고가용성을 위한것이며, 혹시 leader가 죽었을 경우 follower 중 하나가 leader가 되어야 하기 때문에, follower는 leader와 싱크를 맞추고 있는 것 ( In-Sync Replica, ISR )<li>예를 들어, 3대의 Broker Server에 대하여, topic-1에 4개의 Partition이 존재할 때, –replication-factor=2 로 설정한다고 가정 ( Zookeeper가 Partition을 골고루 분배 )<li>Partition1에 메시지를 쓰는 상황일 때, leader partition이 존재하는 Broker2에서 메시지가 생산<li>그리고 follower인 Broker3에 존재하는 Partition은 leader를 복제 ( ISR )<li>만약 leader가 되는 Broker가 다운이 되면, follower가 leader로 선출됩니다.<li>예시는 leader가 1개지만 여러 개의 follower가 있다면, Zookeeper가 leader를 알아서 선출</ul><h1 id="메시지-보존기간">메시지 보존기간</h1><ul><li>클러스터는 쓰여진 메시지를 보존기간동안 유지<li>보존 기간 정책은 log.retention.hours 설정을 통해 가능하며, 기본값은 7일<li>예를 들어, 보존 정책이 2일이면, 2일 뒤에는 공간 확보를 위해 해당 메시지를 폐기<li>데이터 크기에 상관없이 카프카의 성능은 일정하기 때문에 장기간 저장해도 문제는 없으므로, 보존기간을 짧게 잡을 필요는 없음<li>즉, Consumer가 메세지를 소비한다고 해서 메시지가 없어지는게 아니라 보존기간이 지나야 사라짐, 그래서 Consumer가 과거의 offset에 대한 접근을 할 수 있는것<li>Partition이 1개이냐, 2개 이상이냐에 따른 메시지 순서 보장에 대한 자료<br /> https://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-%EC%B2%98%EC%9D%8C-%EC%A0%91%ED%95%98%EB%8A%94-kafka/<br /></ul><h1 id="kafka-command">kafka command</h1><ul><li><p>(1) zookeeper시작<br /> bin\windows\zookeeper-server-start.bat config/zookeeper.properties<br /></p><li><p>(2) kafka server 시작<br /> bin\windows\kafka-server-start.bat config/server.properties<br /></p><li>(3) consumer시작<br /> bin\windows\kafka-console-consumer.bat –bootstrap-server localhost:9092 –topic topic1<br /><ul><li><b>Option</b><li>–from-beginning: 쌓여있던 모든 메시지를 가져옴<br /></ul><li>(4) producer 시작<br /> bin\windows\kafka-console-producer.bat –broker-list localhost:9092 –topic topic1<br /></ul><h1 id="kafka-log4j-configuration-for-java">kafka log4j configuration for java</h1><p>https://alwaysemmyhope.com/ko/java/460988-how-to-enable-kafka-logging-with-log4j-java-log4j-apache-kafka-slf4j.html<br /></p><h4 id="출처-및-참고">출처 및 참고</h4><ul><li><a href="https://victorydntmd.tistory.com/344?category=798367">https://victorydntmd.tistory.com/344?category=798367</a><li><a href="https://team-platform.tistory.com/13">https://team-platform.tistory.com/13</a><li><a href="http://junil-hwang.com/blog/kafka-java/">http://junil-hwang.com/blog/kafka-java/</a><li><a href="https://oboki.net/workspace/bigdata/kafka/kafka-producer-consumer-sample/">https://oboki.net/workspace/bigdata/kafka/kafka-producer-consumer-sample/</a><li><a href="https://www.youtube.com/watch?v=waw0XXNX-uQ&amp;list=PL3Re5Ri5rZmkY46j6WcJXQYRlDRZSUQ1j">https://www.youtube.com/watch?v=waw0XXNX-uQ&amp;list=PL3Re5Ri5rZmkY46j6WcJXQYRlDRZSUQ1j</a><li><a href="https://colinch4.github.io/2021-01-15/404_consumer_core/">https://colinch4.github.io/2021-01-15/404_consumer_core/</a></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/backend/'>Backend</a>, <a href='/categories/kafka/'>Kafka</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/kafka/" class="post-tag no-text-decoration" >kafka</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Kafka 개요 - Youngho's Devlog&url=https://jeonyoungho.github.io/posts/Kafka-%EA%B0%9C%EC%9A%94/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Kafka 개요 - Youngho's Devlog&u=https://jeonyoungho.github.io/posts/Kafka-%EA%B0%9C%EC%9A%94/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Kafka 개요 - Youngho's Devlog&url=https://jeonyoungho.github.io/posts/Kafka-%EA%B0%9C%EC%9A%94/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-5958719204143086" data-ad-slot="1982371670" data-ad-format="auto" data-full-width-responsive="true"></ins> <script> (adsbygoogle = window.adsbygoogle || []).push({}); </script> <ins class="adsbygoogle" style="display:block" data-ad-format="autorelaxed" data-ad-client="ca-pub-5958719204143086" data-ad-slot="5918543412"></ins> <script> (adsbygoogle = window.adsbygoogle || []).push({}); </script> <script src="https://utteranc.es/client.js" repo="jeonyoungho/jeonyoungho.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/Kafka-%EB%A9%94%EC%8B%9C%EC%A7%80-%EC%A0%84%EB%8B%AC-%EB%B3%B4%EC%9E%A5-%EB%B0%A9%EC%8B%9D/">Kafka 메시지 전달 보장 방식</a><li><a href="/posts/Transactional-Outbox-%ED%8C%A8%ED%84%B4/">Transactional Outbox 패턴</a><li><a href="/posts/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EC%9D%B8%EB%8D%B1%EC%8A%A4-%EC%A1%B0%EA%B0%81%ED%99%94/">데이터베이스 인덱스 조각화(Fragmentation)</a><li><a href="/posts/Kafka-DeadLetter-%EA%B4%80%EB%A6%AC/">Kafka DeadLetter 관리</a><li><a href="/posts/Redis-%ED%8A%B9%EC%A7%95/">Redis 특징</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/java/">java</a> <a class="post-tag" href="/tags/spring/">spring</a> <a class="post-tag" href="/tags/jpa/">jpa</a> <a class="post-tag" href="/tags/effectivejava/">effectivejava</a> <a class="post-tag" href="/tags/react/">react</a> <a class="post-tag" href="/tags/frontend/">frontend</a> <a class="post-tag" href="/tags/es6/">es6</a> <a class="post-tag" href="/tags/velopert/">velopert</a> <a class="post-tag" href="/tags/javascript/">javascript</a> <a class="post-tag" href="/tags/poiemaweb/">poiemaweb</a></div></div></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/Kafka-DeadLetter-%EA%B4%80%EB%A6%AC/"><div class="card-body"> <span class="timeago small" > May 11 <i class="unloaded">2025-05-11T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Kafka DeadLetter 관리</h3><div class="text-muted small"><p> MSA 환경에서 이벤트 기반 아키텍처(EDA)를 적용할때 Kafka가 주로 사용되곤 한다. 카프카 Consumer 메시지 처리 실패시 dead-letter를 어떻게 관리하고 재시도 전략을 수립하면 좋을지 깊게 고찰해보자. (잘못된 내용 및 피드백은 코멘트로 남겨주시면 최대한 빠르게 확인해보겠습니다😃) 가장 간단하게는 spring-kafka에서 제공...</p></div></div></a></div><div class="card"> <a href="/posts/Kafka-%EA%B8%B0%EB%B3%B8-%EC%8B%A4%EC%8A%B5/"><div class="card-body"> <span class="timeago small" > Jun 30, 2021 <i class="unloaded">2021-06-30T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Kafka 기본 실습</h3><div class="text-muted small"><p> Kafka-실습1 Kafka 설치 1) homebrew를 통한 kafka 설치 1 brew install kafka Kafka 실행 2) Kafka를 실행하기 전 zookeeper를 먼저 시작 1 brew services start zookeeper 3) Kafka 시작 1 brew services start kafka 4) ...</p></div></div></a></div><div class="card"> <a href="/posts/Kafka-%EC%B9%B4%ED%94%84%EC%B9%B4-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0-%EA%B5%AC%EC%B6%95-%EC%8B%A4%EC%8A%B5-with-AWS-EC2/"><div class="card-body"> <span class="timeago small" > Jun 30, 2021 <i class="unloaded">2021-06-30T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Kafka 카프카 클러스터 구축 실습 with AWS EC2</h3><div class="text-muted small"><p> Kafka 카프카 클러스터 구축 실습 with AWS EC2 aws의 ec2 서버 3대를 발급받아서 카프카를 설치 후 console producer와 console consumer로 연동해보는 실습 아파치 카프카를 실행하기 위해선 2가지의 애플리케이션의 요구 zookeeper: 카프카 관련 정보를 저장하는 역할 ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/JVM%EA%B5%AC%EC%A1%B0/" class="btn btn-outline-primary" prompt="Older"><p>[Java] JVM 구조</p></a> <a href="/posts/Kafka-%EA%B8%B0%EB%B3%B8-%EC%8B%A4%EC%8A%B5/" class="btn btn-outline-primary" prompt="Newer"><p>Kafka 기본 실습</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2025 <a href="https://twitter.com/jeonyoungho_o">jeonyoungho</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/java/">java</a> <a class="post-tag" href="/tags/spring/">spring</a> <a class="post-tag" href="/tags/jpa/">jpa</a> <a class="post-tag" href="/tags/effectivejava/">effectivejava</a> <a class="post-tag" href="/tags/react/">react</a> <a class="post-tag" href="/tags/frontend/">frontend</a> <a class="post-tag" href="/tags/es6/">es6</a> <a class="post-tag" href="/tags/velopert/">velopert</a> <a class="post-tag" href="/tags/javascript/">javascript</a> <a class="post-tag" href="/tags/poiemaweb/">poiemaweb</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://jeonyoungho.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
